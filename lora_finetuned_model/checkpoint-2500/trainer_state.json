{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 26.25712776184082,
      "learning_rate": 0.00019936000000000002,
      "loss": 11.5655,
      "step": 10
    },
    {
      "epoch": 0.008,
      "grad_norm": 7.925449848175049,
      "learning_rate": 0.00019856000000000002,
      "loss": 4.1079,
      "step": 20
    },
    {
      "epoch": 0.012,
      "grad_norm": 6.774561882019043,
      "learning_rate": 0.00019776,
      "loss": 3.5125,
      "step": 30
    },
    {
      "epoch": 0.016,
      "grad_norm": 17.88545036315918,
      "learning_rate": 0.00019696,
      "loss": 4.225,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.534512519836426,
      "learning_rate": 0.00019616000000000002,
      "loss": 3.1831,
      "step": 50
    },
    {
      "epoch": 0.024,
      "grad_norm": 3.0825860500335693,
      "learning_rate": 0.00019536,
      "loss": 2.8398,
      "step": 60
    },
    {
      "epoch": 0.028,
      "grad_norm": 3.81373929977417,
      "learning_rate": 0.00019456,
      "loss": 3.0459,
      "step": 70
    },
    {
      "epoch": 0.032,
      "grad_norm": 13.281085014343262,
      "learning_rate": 0.00019376000000000002,
      "loss": 3.3166,
      "step": 80
    },
    {
      "epoch": 0.036,
      "grad_norm": 7.246328353881836,
      "learning_rate": 0.00019296,
      "loss": 3.0205,
      "step": 90
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.213236808776855,
      "learning_rate": 0.00019216,
      "loss": 3.1383,
      "step": 100
    },
    {
      "epoch": 0.044,
      "grad_norm": 4.905717372894287,
      "learning_rate": 0.00019136,
      "loss": 2.6168,
      "step": 110
    },
    {
      "epoch": 0.048,
      "grad_norm": 2.483349084854126,
      "learning_rate": 0.00019056000000000002,
      "loss": 3.2035,
      "step": 120
    },
    {
      "epoch": 0.052,
      "grad_norm": 4.8437180519104,
      "learning_rate": 0.00018976,
      "loss": 3.1436,
      "step": 130
    },
    {
      "epoch": 0.056,
      "grad_norm": 2.6085832118988037,
      "learning_rate": 0.00018896,
      "loss": 2.5877,
      "step": 140
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.710307121276855,
      "learning_rate": 0.00018816000000000001,
      "loss": 2.4134,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 3.9218807220458984,
      "learning_rate": 0.00018736,
      "loss": 2.9014,
      "step": 160
    },
    {
      "epoch": 0.068,
      "grad_norm": 4.328707695007324,
      "learning_rate": 0.00018656,
      "loss": 3.5513,
      "step": 170
    },
    {
      "epoch": 0.072,
      "grad_norm": 4.855556488037109,
      "learning_rate": 0.00018576,
      "loss": 2.5371,
      "step": 180
    },
    {
      "epoch": 0.076,
      "grad_norm": 10.785015106201172,
      "learning_rate": 0.00018504,
      "loss": 2.8542,
      "step": 190
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.925273895263672,
      "learning_rate": 0.00018424,
      "loss": 3.2681,
      "step": 200
    },
    {
      "epoch": 0.084,
      "grad_norm": 8.566752433776855,
      "learning_rate": 0.00018344000000000002,
      "loss": 2.6938,
      "step": 210
    },
    {
      "epoch": 0.088,
      "grad_norm": 4.550623893737793,
      "learning_rate": 0.00018264,
      "loss": 3.1472,
      "step": 220
    },
    {
      "epoch": 0.092,
      "grad_norm": 3.209768056869507,
      "learning_rate": 0.00018184,
      "loss": 3.3203,
      "step": 230
    },
    {
      "epoch": 0.096,
      "grad_norm": 1.8214088678359985,
      "learning_rate": 0.00018104000000000001,
      "loss": 2.9734,
      "step": 240
    },
    {
      "epoch": 0.1,
      "grad_norm": 6.156130313873291,
      "learning_rate": 0.00018024,
      "loss": 3.1415,
      "step": 250
    },
    {
      "epoch": 0.104,
      "grad_norm": 2.6791892051696777,
      "learning_rate": 0.00017944,
      "loss": 2.7352,
      "step": 260
    },
    {
      "epoch": 0.108,
      "grad_norm": 5.497020721435547,
      "learning_rate": 0.00017864,
      "loss": 2.0002,
      "step": 270
    },
    {
      "epoch": 0.112,
      "grad_norm": 5.644614219665527,
      "learning_rate": 0.00017784000000000002,
      "loss": 2.444,
      "step": 280
    },
    {
      "epoch": 0.116,
      "grad_norm": 3.0167882442474365,
      "learning_rate": 0.00017704,
      "loss": 2.3489,
      "step": 290
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.8656864166259766,
      "learning_rate": 0.00017624,
      "loss": 2.9623,
      "step": 300
    },
    {
      "epoch": 0.124,
      "grad_norm": 2.075122594833374,
      "learning_rate": 0.00017544000000000001,
      "loss": 3.0704,
      "step": 310
    },
    {
      "epoch": 0.128,
      "grad_norm": 6.366028785705566,
      "learning_rate": 0.00017464,
      "loss": 3.1811,
      "step": 320
    },
    {
      "epoch": 0.132,
      "grad_norm": 1.8946678638458252,
      "learning_rate": 0.00017384,
      "loss": 2.3623,
      "step": 330
    },
    {
      "epoch": 0.136,
      "grad_norm": 7.306964874267578,
      "learning_rate": 0.00017304,
      "loss": 2.9358,
      "step": 340
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.660494565963745,
      "learning_rate": 0.00017224,
      "loss": 2.6918,
      "step": 350
    },
    {
      "epoch": 0.144,
      "grad_norm": 3.221780776977539,
      "learning_rate": 0.00017144,
      "loss": 2.0386,
      "step": 360
    },
    {
      "epoch": 0.148,
      "grad_norm": 4.426482677459717,
      "learning_rate": 0.00017064,
      "loss": 2.9445,
      "step": 370
    },
    {
      "epoch": 0.152,
      "grad_norm": 5.105274677276611,
      "learning_rate": 0.00016984,
      "loss": 2.9284,
      "step": 380
    },
    {
      "epoch": 0.156,
      "grad_norm": 3.482124090194702,
      "learning_rate": 0.00016904,
      "loss": 2.7415,
      "step": 390
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7998239994049072,
      "learning_rate": 0.00016824,
      "loss": 2.1428,
      "step": 400
    },
    {
      "epoch": 0.164,
      "grad_norm": 2.092409610748291,
      "learning_rate": 0.00016744,
      "loss": 2.3394,
      "step": 410
    },
    {
      "epoch": 0.168,
      "grad_norm": 11.680436134338379,
      "learning_rate": 0.00016664000000000002,
      "loss": 1.9674,
      "step": 420
    },
    {
      "epoch": 0.172,
      "grad_norm": 3.3576996326446533,
      "learning_rate": 0.00016584000000000002,
      "loss": 2.6417,
      "step": 430
    },
    {
      "epoch": 0.176,
      "grad_norm": 7.857518672943115,
      "learning_rate": 0.00016504,
      "loss": 2.537,
      "step": 440
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.157836437225342,
      "learning_rate": 0.00016424,
      "loss": 2.6472,
      "step": 450
    },
    {
      "epoch": 0.184,
      "grad_norm": 6.716128826141357,
      "learning_rate": 0.00016344000000000002,
      "loss": 3.0127,
      "step": 460
    },
    {
      "epoch": 0.188,
      "grad_norm": 2.317035675048828,
      "learning_rate": 0.00016264,
      "loss": 2.952,
      "step": 470
    },
    {
      "epoch": 0.192,
      "grad_norm": 3.0743918418884277,
      "learning_rate": 0.00016184,
      "loss": 2.5134,
      "step": 480
    },
    {
      "epoch": 0.196,
      "grad_norm": 3.8446333408355713,
      "learning_rate": 0.00016104000000000002,
      "loss": 2.6116,
      "step": 490
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.1493935585021973,
      "learning_rate": 0.00016024000000000002,
      "loss": 2.6034,
      "step": 500
    },
    {
      "epoch": 0.204,
      "grad_norm": 2.7423293590545654,
      "learning_rate": 0.00015944,
      "loss": 2.5817,
      "step": 510
    },
    {
      "epoch": 0.208,
      "grad_norm": 5.701347351074219,
      "learning_rate": 0.00015864,
      "loss": 2.5484,
      "step": 520
    },
    {
      "epoch": 0.212,
      "grad_norm": 3.113996744155884,
      "learning_rate": 0.00015784000000000002,
      "loss": 3.125,
      "step": 530
    },
    {
      "epoch": 0.216,
      "grad_norm": 7.526989459991455,
      "learning_rate": 0.00015704,
      "loss": 2.3555,
      "step": 540
    },
    {
      "epoch": 0.22,
      "grad_norm": 4.906931400299072,
      "learning_rate": 0.00015624,
      "loss": 3.2011,
      "step": 550
    },
    {
      "epoch": 0.224,
      "grad_norm": 2.533292293548584,
      "learning_rate": 0.00015544000000000002,
      "loss": 2.3719,
      "step": 560
    },
    {
      "epoch": 0.228,
      "grad_norm": 2.5517141819000244,
      "learning_rate": 0.00015464,
      "loss": 2.6851,
      "step": 570
    },
    {
      "epoch": 0.232,
      "grad_norm": 1.9903818368911743,
      "learning_rate": 0.00015384,
      "loss": 2.4717,
      "step": 580
    },
    {
      "epoch": 0.236,
      "grad_norm": 3.7168028354644775,
      "learning_rate": 0.00015304,
      "loss": 3.2754,
      "step": 590
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.2636470794677734,
      "learning_rate": 0.00015224,
      "loss": 2.8019,
      "step": 600
    },
    {
      "epoch": 0.244,
      "grad_norm": 7.774837493896484,
      "learning_rate": 0.00015144,
      "loss": 2.8722,
      "step": 610
    },
    {
      "epoch": 0.248,
      "grad_norm": 4.013894557952881,
      "learning_rate": 0.00015064,
      "loss": 3.0671,
      "step": 620
    },
    {
      "epoch": 0.252,
      "grad_norm": 4.114460468292236,
      "learning_rate": 0.00014984000000000002,
      "loss": 3.805,
      "step": 630
    },
    {
      "epoch": 0.256,
      "grad_norm": 3.5534121990203857,
      "learning_rate": 0.00014904,
      "loss": 2.3344,
      "step": 640
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.2447290420532227,
      "learning_rate": 0.00014824,
      "loss": 2.6967,
      "step": 650
    },
    {
      "epoch": 0.264,
      "grad_norm": 5.43511438369751,
      "learning_rate": 0.00014744,
      "loss": 2.4799,
      "step": 660
    },
    {
      "epoch": 0.268,
      "grad_norm": 5.912671089172363,
      "learning_rate": 0.00014664,
      "loss": 2.8616,
      "step": 670
    },
    {
      "epoch": 0.272,
      "grad_norm": 7.214398384094238,
      "learning_rate": 0.00014584,
      "loss": 2.9935,
      "step": 680
    },
    {
      "epoch": 0.276,
      "grad_norm": 2.2152059078216553,
      "learning_rate": 0.00014504,
      "loss": 2.968,
      "step": 690
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.098527431488037,
      "learning_rate": 0.00014424,
      "loss": 3.0125,
      "step": 700
    },
    {
      "epoch": 0.284,
      "grad_norm": 2.621385097503662,
      "learning_rate": 0.00014344,
      "loss": 3.0338,
      "step": 710
    },
    {
      "epoch": 0.288,
      "grad_norm": 10.99438762664795,
      "learning_rate": 0.00014264,
      "loss": 2.9212,
      "step": 720
    },
    {
      "epoch": 0.292,
      "grad_norm": 2.1771600246429443,
      "learning_rate": 0.00014184,
      "loss": 3.4831,
      "step": 730
    },
    {
      "epoch": 0.296,
      "grad_norm": 3.5227344036102295,
      "learning_rate": 0.00014104000000000002,
      "loss": 2.7087,
      "step": 740
    },
    {
      "epoch": 0.3,
      "grad_norm": 5.9127631187438965,
      "learning_rate": 0.00014024000000000003,
      "loss": 2.5615,
      "step": 750
    },
    {
      "epoch": 0.304,
      "grad_norm": 3.072216510772705,
      "learning_rate": 0.00013944,
      "loss": 2.819,
      "step": 760
    },
    {
      "epoch": 0.308,
      "grad_norm": 3.285301685333252,
      "learning_rate": 0.00013864000000000001,
      "loss": 3.2581,
      "step": 770
    },
    {
      "epoch": 0.312,
      "grad_norm": 2.198322296142578,
      "learning_rate": 0.00013784000000000002,
      "loss": 2.8204,
      "step": 780
    },
    {
      "epoch": 0.316,
      "grad_norm": 4.739543437957764,
      "learning_rate": 0.00013704,
      "loss": 2.8597,
      "step": 790
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.54742431640625,
      "learning_rate": 0.00013624,
      "loss": 2.3202,
      "step": 800
    },
    {
      "epoch": 0.324,
      "grad_norm": 4.15990686416626,
      "learning_rate": 0.00013544000000000002,
      "loss": 2.559,
      "step": 810
    },
    {
      "epoch": 0.328,
      "grad_norm": 2.4718551635742188,
      "learning_rate": 0.00013464,
      "loss": 2.6218,
      "step": 820
    },
    {
      "epoch": 0.332,
      "grad_norm": 5.588024616241455,
      "learning_rate": 0.00013384,
      "loss": 3.1712,
      "step": 830
    },
    {
      "epoch": 0.336,
      "grad_norm": 3.8387296199798584,
      "learning_rate": 0.00013304000000000001,
      "loss": 2.4092,
      "step": 840
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.6084659099578857,
      "learning_rate": 0.00013224000000000002,
      "loss": 2.4141,
      "step": 850
    },
    {
      "epoch": 0.344,
      "grad_norm": 3.552569627761841,
      "learning_rate": 0.00013144,
      "loss": 2.5181,
      "step": 860
    },
    {
      "epoch": 0.348,
      "grad_norm": 3.508052349090576,
      "learning_rate": 0.00013064,
      "loss": 2.8985,
      "step": 870
    },
    {
      "epoch": 0.352,
      "grad_norm": 2.3661458492279053,
      "learning_rate": 0.00012984000000000002,
      "loss": 2.3712,
      "step": 880
    },
    {
      "epoch": 0.356,
      "grad_norm": 2.19282865524292,
      "learning_rate": 0.00012904,
      "loss": 2.7207,
      "step": 890
    },
    {
      "epoch": 0.36,
      "grad_norm": 5.366755962371826,
      "learning_rate": 0.00012824,
      "loss": 2.6853,
      "step": 900
    },
    {
      "epoch": 0.364,
      "grad_norm": 4.344689846038818,
      "learning_rate": 0.00012744,
      "loss": 3.0015,
      "step": 910
    },
    {
      "epoch": 0.368,
      "grad_norm": 3.6914145946502686,
      "learning_rate": 0.00012664,
      "loss": 2.932,
      "step": 920
    },
    {
      "epoch": 0.372,
      "grad_norm": 1.0394222736358643,
      "learning_rate": 0.00012584,
      "loss": 2.0781,
      "step": 930
    },
    {
      "epoch": 0.376,
      "grad_norm": 8.898691177368164,
      "learning_rate": 0.00012504,
      "loss": 3.2656,
      "step": 940
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.1486167907714844,
      "learning_rate": 0.00012424,
      "loss": 2.9718,
      "step": 950
    },
    {
      "epoch": 0.384,
      "grad_norm": 4.956127166748047,
      "learning_rate": 0.00012344,
      "loss": 3.0484,
      "step": 960
    },
    {
      "epoch": 0.388,
      "grad_norm": 1.4643878936767578,
      "learning_rate": 0.00012264,
      "loss": 2.723,
      "step": 970
    },
    {
      "epoch": 0.392,
      "grad_norm": 5.639340877532959,
      "learning_rate": 0.00012184,
      "loss": 2.5297,
      "step": 980
    },
    {
      "epoch": 0.396,
      "grad_norm": 9.112298965454102,
      "learning_rate": 0.00012103999999999999,
      "loss": 3.1603,
      "step": 990
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.088847637176514,
      "learning_rate": 0.00012024,
      "loss": 2.8499,
      "step": 1000
    },
    {
      "epoch": 0.404,
      "grad_norm": 2.193911075592041,
      "learning_rate": 0.00011944,
      "loss": 2.6519,
      "step": 1010
    },
    {
      "epoch": 0.408,
      "grad_norm": 6.179723739624023,
      "learning_rate": 0.00011863999999999999,
      "loss": 2.6717,
      "step": 1020
    },
    {
      "epoch": 0.412,
      "grad_norm": 9.604729652404785,
      "learning_rate": 0.00011784,
      "loss": 2.6258,
      "step": 1030
    },
    {
      "epoch": 0.416,
      "grad_norm": 5.686905860900879,
      "learning_rate": 0.00011704000000000002,
      "loss": 2.2646,
      "step": 1040
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.3569772243499756,
      "learning_rate": 0.00011624000000000001,
      "loss": 2.7934,
      "step": 1050
    },
    {
      "epoch": 0.424,
      "grad_norm": 2.633336305618286,
      "learning_rate": 0.00011544000000000002,
      "loss": 3.251,
      "step": 1060
    },
    {
      "epoch": 0.428,
      "grad_norm": 2.7746541500091553,
      "learning_rate": 0.00011464000000000001,
      "loss": 2.5198,
      "step": 1070
    },
    {
      "epoch": 0.432,
      "grad_norm": 11.118148803710938,
      "learning_rate": 0.00011384000000000001,
      "loss": 2.838,
      "step": 1080
    },
    {
      "epoch": 0.436,
      "grad_norm": 4.043979644775391,
      "learning_rate": 0.00011304000000000002,
      "loss": 2.1426,
      "step": 1090
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.500286817550659,
      "learning_rate": 0.00011224000000000001,
      "loss": 3.2926,
      "step": 1100
    },
    {
      "epoch": 0.444,
      "grad_norm": 5.023506164550781,
      "learning_rate": 0.00011144000000000002,
      "loss": 2.4982,
      "step": 1110
    },
    {
      "epoch": 0.448,
      "grad_norm": 4.099506378173828,
      "learning_rate": 0.00011064000000000001,
      "loss": 2.8323,
      "step": 1120
    },
    {
      "epoch": 0.452,
      "grad_norm": 3.2863943576812744,
      "learning_rate": 0.00010984,
      "loss": 2.8317,
      "step": 1130
    },
    {
      "epoch": 0.456,
      "grad_norm": 5.202643394470215,
      "learning_rate": 0.00010904000000000001,
      "loss": 2.2989,
      "step": 1140
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1064090728759766,
      "learning_rate": 0.00010824000000000001,
      "loss": 2.6354,
      "step": 1150
    },
    {
      "epoch": 0.464,
      "grad_norm": 2.6943819522857666,
      "learning_rate": 0.00010744,
      "loss": 2.6105,
      "step": 1160
    },
    {
      "epoch": 0.468,
      "grad_norm": 7.05342435836792,
      "learning_rate": 0.00010664000000000001,
      "loss": 2.2549,
      "step": 1170
    },
    {
      "epoch": 0.472,
      "grad_norm": 1.4735835790634155,
      "learning_rate": 0.00010584,
      "loss": 2.4895,
      "step": 1180
    },
    {
      "epoch": 0.476,
      "grad_norm": 12.799406051635742,
      "learning_rate": 0.00010504000000000001,
      "loss": 3.3116,
      "step": 1190
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.002612829208374,
      "learning_rate": 0.00010424,
      "loss": 2.371,
      "step": 1200
    },
    {
      "epoch": 0.484,
      "grad_norm": 1.9631733894348145,
      "learning_rate": 0.00010344,
      "loss": 2.8727,
      "step": 1210
    },
    {
      "epoch": 0.488,
      "grad_norm": 3.947960138320923,
      "learning_rate": 0.00010264,
      "loss": 2.8043,
      "step": 1220
    },
    {
      "epoch": 0.492,
      "grad_norm": 2.6545162200927734,
      "learning_rate": 0.00010184,
      "loss": 3.1405,
      "step": 1230
    },
    {
      "epoch": 0.496,
      "grad_norm": 4.227851867675781,
      "learning_rate": 0.00010104,
      "loss": 3.305,
      "step": 1240
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.1856768131256104,
      "learning_rate": 0.00010024,
      "loss": 3.0785,
      "step": 1250
    },
    {
      "epoch": 0.504,
      "grad_norm": 5.211544513702393,
      "learning_rate": 9.944e-05,
      "loss": 2.4561,
      "step": 1260
    },
    {
      "epoch": 0.508,
      "grad_norm": 3.5431861877441406,
      "learning_rate": 9.864e-05,
      "loss": 2.6722,
      "step": 1270
    },
    {
      "epoch": 0.512,
      "grad_norm": 2.4072153568267822,
      "learning_rate": 9.784000000000001e-05,
      "loss": 2.3115,
      "step": 1280
    },
    {
      "epoch": 0.516,
      "grad_norm": 1.7168869972229004,
      "learning_rate": 9.704e-05,
      "loss": 2.2899,
      "step": 1290
    },
    {
      "epoch": 0.52,
      "grad_norm": 5.737039566040039,
      "learning_rate": 9.624000000000001e-05,
      "loss": 2.6403,
      "step": 1300
    },
    {
      "epoch": 0.524,
      "grad_norm": 5.469470977783203,
      "learning_rate": 9.544000000000001e-05,
      "loss": 3.3529,
      "step": 1310
    },
    {
      "epoch": 0.528,
      "grad_norm": 5.779764175415039,
      "learning_rate": 9.464e-05,
      "loss": 3.143,
      "step": 1320
    },
    {
      "epoch": 0.532,
      "grad_norm": 1.3577079772949219,
      "learning_rate": 9.384000000000001e-05,
      "loss": 2.2536,
      "step": 1330
    },
    {
      "epoch": 0.536,
      "grad_norm": 6.392264366149902,
      "learning_rate": 9.304e-05,
      "loss": 2.6802,
      "step": 1340
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.834693193435669,
      "learning_rate": 9.224e-05,
      "loss": 2.1904,
      "step": 1350
    },
    {
      "epoch": 0.544,
      "grad_norm": 1.258154034614563,
      "learning_rate": 9.144e-05,
      "loss": 2.3768,
      "step": 1360
    },
    {
      "epoch": 0.548,
      "grad_norm": 3.51832914352417,
      "learning_rate": 9.064e-05,
      "loss": 2.5636,
      "step": 1370
    },
    {
      "epoch": 0.552,
      "grad_norm": 3.894228935241699,
      "learning_rate": 8.984000000000001e-05,
      "loss": 3.3703,
      "step": 1380
    },
    {
      "epoch": 0.556,
      "grad_norm": 4.097358226776123,
      "learning_rate": 8.904e-05,
      "loss": 2.9101,
      "step": 1390
    },
    {
      "epoch": 0.56,
      "grad_norm": 6.514798641204834,
      "learning_rate": 8.824e-05,
      "loss": 2.7107,
      "step": 1400
    },
    {
      "epoch": 0.564,
      "grad_norm": 4.484959602355957,
      "learning_rate": 8.744e-05,
      "loss": 3.0317,
      "step": 1410
    },
    {
      "epoch": 0.568,
      "grad_norm": 4.359796524047852,
      "learning_rate": 8.664e-05,
      "loss": 2.7035,
      "step": 1420
    },
    {
      "epoch": 0.572,
      "grad_norm": 3.0117640495300293,
      "learning_rate": 8.584e-05,
      "loss": 2.4595,
      "step": 1430
    },
    {
      "epoch": 0.576,
      "grad_norm": 8.182744026184082,
      "learning_rate": 8.504000000000001e-05,
      "loss": 2.273,
      "step": 1440
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.0323777198791504,
      "learning_rate": 8.424e-05,
      "loss": 1.8981,
      "step": 1450
    },
    {
      "epoch": 0.584,
      "grad_norm": 1.4915701150894165,
      "learning_rate": 8.344e-05,
      "loss": 1.8735,
      "step": 1460
    },
    {
      "epoch": 0.588,
      "grad_norm": 3.5312883853912354,
      "learning_rate": 8.264000000000001e-05,
      "loss": 2.4045,
      "step": 1470
    },
    {
      "epoch": 0.592,
      "grad_norm": 7.573811054229736,
      "learning_rate": 8.184e-05,
      "loss": 2.2813,
      "step": 1480
    },
    {
      "epoch": 0.596,
      "grad_norm": 1.9153945446014404,
      "learning_rate": 8.104000000000001e-05,
      "loss": 2.4538,
      "step": 1490
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9900445938110352,
      "learning_rate": 8.024e-05,
      "loss": 2.8661,
      "step": 1500
    },
    {
      "epoch": 0.604,
      "grad_norm": 1.703013300895691,
      "learning_rate": 7.944e-05,
      "loss": 2.1832,
      "step": 1510
    },
    {
      "epoch": 0.608,
      "grad_norm": 5.915231704711914,
      "learning_rate": 7.864e-05,
      "loss": 3.2277,
      "step": 1520
    },
    {
      "epoch": 0.612,
      "grad_norm": 4.406009197235107,
      "learning_rate": 7.784e-05,
      "loss": 2.6974,
      "step": 1530
    },
    {
      "epoch": 0.616,
      "grad_norm": 1.401566505432129,
      "learning_rate": 7.704000000000001e-05,
      "loss": 2.3906,
      "step": 1540
    },
    {
      "epoch": 0.62,
      "grad_norm": 5.946497917175293,
      "learning_rate": 7.624e-05,
      "loss": 2.6478,
      "step": 1550
    },
    {
      "epoch": 0.624,
      "grad_norm": 6.400149345397949,
      "learning_rate": 7.544e-05,
      "loss": 2.8364,
      "step": 1560
    },
    {
      "epoch": 0.628,
      "grad_norm": 2.216644525527954,
      "learning_rate": 7.464e-05,
      "loss": 2.8447,
      "step": 1570
    },
    {
      "epoch": 0.632,
      "grad_norm": 3.7146599292755127,
      "learning_rate": 7.384e-05,
      "loss": 2.4218,
      "step": 1580
    },
    {
      "epoch": 0.636,
      "grad_norm": 2.0778236389160156,
      "learning_rate": 7.304e-05,
      "loss": 3.1424,
      "step": 1590
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.031505823135376,
      "learning_rate": 7.224000000000001e-05,
      "loss": 2.4805,
      "step": 1600
    },
    {
      "epoch": 0.644,
      "grad_norm": 5.97161340713501,
      "learning_rate": 7.144000000000001e-05,
      "loss": 3.1663,
      "step": 1610
    },
    {
      "epoch": 0.648,
      "grad_norm": 3.5878255367279053,
      "learning_rate": 7.064e-05,
      "loss": 2.596,
      "step": 1620
    },
    {
      "epoch": 0.652,
      "grad_norm": 4.1815690994262695,
      "learning_rate": 6.984000000000001e-05,
      "loss": 2.826,
      "step": 1630
    },
    {
      "epoch": 0.656,
      "grad_norm": 2.166465997695923,
      "learning_rate": 6.904e-05,
      "loss": 3.0006,
      "step": 1640
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.003352403640747,
      "learning_rate": 6.824e-05,
      "loss": 2.9614,
      "step": 1650
    },
    {
      "epoch": 0.664,
      "grad_norm": 4.2177252769470215,
      "learning_rate": 6.744e-05,
      "loss": 2.5655,
      "step": 1660
    },
    {
      "epoch": 0.668,
      "grad_norm": 8.390851020812988,
      "learning_rate": 6.664e-05,
      "loss": 2.5065,
      "step": 1670
    },
    {
      "epoch": 0.672,
      "grad_norm": 1.2275639772415161,
      "learning_rate": 6.584e-05,
      "loss": 2.7241,
      "step": 1680
    },
    {
      "epoch": 0.676,
      "grad_norm": 4.081910610198975,
      "learning_rate": 6.504e-05,
      "loss": 2.5338,
      "step": 1690
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5925711393356323,
      "learning_rate": 6.424e-05,
      "loss": 3.1373,
      "step": 1700
    },
    {
      "epoch": 0.684,
      "grad_norm": 1.414018988609314,
      "learning_rate": 6.344e-05,
      "loss": 2.477,
      "step": 1710
    },
    {
      "epoch": 0.688,
      "grad_norm": 3.4983913898468018,
      "learning_rate": 6.264e-05,
      "loss": 2.3204,
      "step": 1720
    },
    {
      "epoch": 0.692,
      "grad_norm": 1.3935546875,
      "learning_rate": 6.184e-05,
      "loss": 2.471,
      "step": 1730
    },
    {
      "epoch": 0.696,
      "grad_norm": 3.5138914585113525,
      "learning_rate": 6.104000000000001e-05,
      "loss": 1.8944,
      "step": 1740
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.4612908363342285,
      "learning_rate": 6.0240000000000006e-05,
      "loss": 3.07,
      "step": 1750
    },
    {
      "epoch": 0.704,
      "grad_norm": 3.417356491088867,
      "learning_rate": 5.944000000000001e-05,
      "loss": 2.7243,
      "step": 1760
    },
    {
      "epoch": 0.708,
      "grad_norm": 2.8379342555999756,
      "learning_rate": 5.864000000000001e-05,
      "loss": 2.2483,
      "step": 1770
    },
    {
      "epoch": 0.712,
      "grad_norm": 3.9735586643218994,
      "learning_rate": 5.784000000000001e-05,
      "loss": 2.9243,
      "step": 1780
    },
    {
      "epoch": 0.716,
      "grad_norm": 1.42686128616333,
      "learning_rate": 5.704e-05,
      "loss": 2.0666,
      "step": 1790
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.888123989105225,
      "learning_rate": 5.6240000000000004e-05,
      "loss": 3.1801,
      "step": 1800
    },
    {
      "epoch": 0.724,
      "grad_norm": 4.003087043762207,
      "learning_rate": 5.5440000000000005e-05,
      "loss": 2.4785,
      "step": 1810
    },
    {
      "epoch": 0.728,
      "grad_norm": 2.017557382583618,
      "learning_rate": 5.4640000000000005e-05,
      "loss": 2.2515,
      "step": 1820
    },
    {
      "epoch": 0.732,
      "grad_norm": 1.9098795652389526,
      "learning_rate": 5.384e-05,
      "loss": 2.6652,
      "step": 1830
    },
    {
      "epoch": 0.736,
      "grad_norm": 4.612936973571777,
      "learning_rate": 5.304e-05,
      "loss": 2.443,
      "step": 1840
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.790792465209961,
      "learning_rate": 5.224e-05,
      "loss": 3.1838,
      "step": 1850
    },
    {
      "epoch": 0.744,
      "grad_norm": 2.402665376663208,
      "learning_rate": 5.144e-05,
      "loss": 2.5443,
      "step": 1860
    },
    {
      "epoch": 0.748,
      "grad_norm": 1.711499571800232,
      "learning_rate": 5.0639999999999996e-05,
      "loss": 2.5139,
      "step": 1870
    },
    {
      "epoch": 0.752,
      "grad_norm": 6.714399814605713,
      "learning_rate": 4.9840000000000004e-05,
      "loss": 2.5541,
      "step": 1880
    },
    {
      "epoch": 0.756,
      "grad_norm": 4.574942111968994,
      "learning_rate": 4.9040000000000005e-05,
      "loss": 2.7892,
      "step": 1890
    },
    {
      "epoch": 0.76,
      "grad_norm": 5.238796710968018,
      "learning_rate": 4.824e-05,
      "loss": 3.4124,
      "step": 1900
    },
    {
      "epoch": 0.764,
      "grad_norm": 3.550894021987915,
      "learning_rate": 4.744e-05,
      "loss": 2.5563,
      "step": 1910
    },
    {
      "epoch": 0.768,
      "grad_norm": 2.944748878479004,
      "learning_rate": 4.664e-05,
      "loss": 2.8553,
      "step": 1920
    },
    {
      "epoch": 0.772,
      "grad_norm": 1.525234580039978,
      "learning_rate": 4.584e-05,
      "loss": 2.2392,
      "step": 1930
    },
    {
      "epoch": 0.776,
      "grad_norm": 1.3757684230804443,
      "learning_rate": 4.504e-05,
      "loss": 2.3212,
      "step": 1940
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8199578523635864,
      "learning_rate": 4.424e-05,
      "loss": 2.4607,
      "step": 1950
    },
    {
      "epoch": 0.784,
      "grad_norm": 3.798166036605835,
      "learning_rate": 4.3440000000000004e-05,
      "loss": 3.583,
      "step": 1960
    },
    {
      "epoch": 0.788,
      "grad_norm": 5.787895202636719,
      "learning_rate": 4.2640000000000005e-05,
      "loss": 2.7115,
      "step": 1970
    },
    {
      "epoch": 0.792,
      "grad_norm": 4.771243572235107,
      "learning_rate": 4.184e-05,
      "loss": 2.5779,
      "step": 1980
    },
    {
      "epoch": 0.796,
      "grad_norm": 2.0302977561950684,
      "learning_rate": 4.104e-05,
      "loss": 2.374,
      "step": 1990
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.760958433151245,
      "learning_rate": 4.024e-05,
      "loss": 2.0678,
      "step": 2000
    },
    {
      "epoch": 0.804,
      "grad_norm": 5.139319896697998,
      "learning_rate": 3.944e-05,
      "loss": 3.0303,
      "step": 2010
    },
    {
      "epoch": 0.808,
      "grad_norm": 1.6067359447479248,
      "learning_rate": 3.864e-05,
      "loss": 2.6141,
      "step": 2020
    },
    {
      "epoch": 0.812,
      "grad_norm": 2.1677145957946777,
      "learning_rate": 3.7840000000000004e-05,
      "loss": 3.0223,
      "step": 2030
    },
    {
      "epoch": 0.816,
      "grad_norm": 2.2037856578826904,
      "learning_rate": 3.7040000000000005e-05,
      "loss": 2.6258,
      "step": 2040
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.279329776763916,
      "learning_rate": 3.624e-05,
      "loss": 2.5313,
      "step": 2050
    },
    {
      "epoch": 0.824,
      "grad_norm": 4.436463356018066,
      "learning_rate": 3.544e-05,
      "loss": 2.5514,
      "step": 2060
    },
    {
      "epoch": 0.828,
      "grad_norm": 1.3381874561309814,
      "learning_rate": 3.464e-05,
      "loss": 2.5651,
      "step": 2070
    },
    {
      "epoch": 0.832,
      "grad_norm": 3.0582244396209717,
      "learning_rate": 3.384e-05,
      "loss": 2.4828,
      "step": 2080
    },
    {
      "epoch": 0.836,
      "grad_norm": 2.8291149139404297,
      "learning_rate": 3.304e-05,
      "loss": 1.9501,
      "step": 2090
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.542567014694214,
      "learning_rate": 3.224e-05,
      "loss": 2.8616,
      "step": 2100
    },
    {
      "epoch": 0.844,
      "grad_norm": 2.6096911430358887,
      "learning_rate": 3.1440000000000004e-05,
      "loss": 2.73,
      "step": 2110
    },
    {
      "epoch": 0.848,
      "grad_norm": 3.1095261573791504,
      "learning_rate": 3.0640000000000005e-05,
      "loss": 2.8009,
      "step": 2120
    },
    {
      "epoch": 0.852,
      "grad_norm": 4.246759414672852,
      "learning_rate": 2.9840000000000002e-05,
      "loss": 2.4851,
      "step": 2130
    },
    {
      "epoch": 0.856,
      "grad_norm": 6.368496417999268,
      "learning_rate": 2.904e-05,
      "loss": 3.0472,
      "step": 2140
    },
    {
      "epoch": 0.86,
      "grad_norm": 4.0822858810424805,
      "learning_rate": 2.824e-05,
      "loss": 2.8879,
      "step": 2150
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.693214774131775,
      "learning_rate": 2.7439999999999998e-05,
      "loss": 2.8965,
      "step": 2160
    },
    {
      "epoch": 0.868,
      "grad_norm": 5.879758358001709,
      "learning_rate": 2.6640000000000002e-05,
      "loss": 2.6816,
      "step": 2170
    },
    {
      "epoch": 0.872,
      "grad_norm": 2.4700372219085693,
      "learning_rate": 2.5840000000000003e-05,
      "loss": 3.0557,
      "step": 2180
    },
    {
      "epoch": 0.876,
      "grad_norm": 3.2263474464416504,
      "learning_rate": 2.504e-05,
      "loss": 2.3719,
      "step": 2190
    },
    {
      "epoch": 0.88,
      "grad_norm": 8.566243171691895,
      "learning_rate": 2.4240000000000002e-05,
      "loss": 2.8522,
      "step": 2200
    },
    {
      "epoch": 0.884,
      "grad_norm": 3.085829973220825,
      "learning_rate": 2.344e-05,
      "loss": 2.6589,
      "step": 2210
    },
    {
      "epoch": 0.888,
      "grad_norm": 3.053799629211426,
      "learning_rate": 2.264e-05,
      "loss": 3.0917,
      "step": 2220
    },
    {
      "epoch": 0.892,
      "grad_norm": 2.9615445137023926,
      "learning_rate": 2.184e-05,
      "loss": 2.2349,
      "step": 2230
    },
    {
      "epoch": 0.896,
      "grad_norm": 2.059128522872925,
      "learning_rate": 2.1040000000000002e-05,
      "loss": 2.1774,
      "step": 2240
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.771596908569336,
      "learning_rate": 2.024e-05,
      "loss": 2.6839,
      "step": 2250
    },
    {
      "epoch": 0.904,
      "grad_norm": 2.5068674087524414,
      "learning_rate": 1.944e-05,
      "loss": 2.5128,
      "step": 2260
    },
    {
      "epoch": 0.908,
      "grad_norm": 4.227013111114502,
      "learning_rate": 1.864e-05,
      "loss": 2.8073,
      "step": 2270
    },
    {
      "epoch": 0.912,
      "grad_norm": 2.2266902923583984,
      "learning_rate": 1.7840000000000002e-05,
      "loss": 2.7358,
      "step": 2280
    },
    {
      "epoch": 0.916,
      "grad_norm": 7.395246505737305,
      "learning_rate": 1.704e-05,
      "loss": 2.3304,
      "step": 2290
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.412909507751465,
      "learning_rate": 1.624e-05,
      "loss": 2.7281,
      "step": 2300
    },
    {
      "epoch": 0.924,
      "grad_norm": 3.0865414142608643,
      "learning_rate": 1.544e-05,
      "loss": 2.7231,
      "step": 2310
    },
    {
      "epoch": 0.928,
      "grad_norm": 2.5895211696624756,
      "learning_rate": 1.464e-05,
      "loss": 2.2649,
      "step": 2320
    },
    {
      "epoch": 0.932,
      "grad_norm": 4.194688320159912,
      "learning_rate": 1.384e-05,
      "loss": 2.9085,
      "step": 2330
    },
    {
      "epoch": 0.936,
      "grad_norm": 1.3872222900390625,
      "learning_rate": 1.3039999999999999e-05,
      "loss": 2.4715,
      "step": 2340
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.3111934661865234,
      "learning_rate": 1.224e-05,
      "loss": 2.3524,
      "step": 2350
    },
    {
      "epoch": 0.944,
      "grad_norm": 3.871561288833618,
      "learning_rate": 1.144e-05,
      "loss": 2.888,
      "step": 2360
    },
    {
      "epoch": 0.948,
      "grad_norm": 5.945121765136719,
      "learning_rate": 1.064e-05,
      "loss": 2.4173,
      "step": 2370
    },
    {
      "epoch": 0.952,
      "grad_norm": 3.82883882522583,
      "learning_rate": 9.84e-06,
      "loss": 2.5587,
      "step": 2380
    },
    {
      "epoch": 0.956,
      "grad_norm": 2.983654022216797,
      "learning_rate": 9.04e-06,
      "loss": 2.2582,
      "step": 2390
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.3729491233825684,
      "learning_rate": 8.24e-06,
      "loss": 2.8877,
      "step": 2400
    },
    {
      "epoch": 0.964,
      "grad_norm": 2.4268805980682373,
      "learning_rate": 7.44e-06,
      "loss": 2.6044,
      "step": 2410
    },
    {
      "epoch": 0.968,
      "grad_norm": 1.8765888214111328,
      "learning_rate": 6.640000000000001e-06,
      "loss": 2.532,
      "step": 2420
    },
    {
      "epoch": 0.972,
      "grad_norm": 7.168894290924072,
      "learning_rate": 5.84e-06,
      "loss": 2.7499,
      "step": 2430
    },
    {
      "epoch": 0.976,
      "grad_norm": 3.1130337715148926,
      "learning_rate": 5.04e-06,
      "loss": 2.6193,
      "step": 2440
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.0954835414886475,
      "learning_rate": 4.24e-06,
      "loss": 2.1707,
      "step": 2450
    },
    {
      "epoch": 0.984,
      "grad_norm": 3.2170209884643555,
      "learning_rate": 3.44e-06,
      "loss": 2.1278,
      "step": 2460
    },
    {
      "epoch": 0.988,
      "grad_norm": 2.6652133464813232,
      "learning_rate": 2.64e-06,
      "loss": 2.7123,
      "step": 2470
    },
    {
      "epoch": 0.992,
      "grad_norm": 2.087790012359619,
      "learning_rate": 1.84e-06,
      "loss": 2.6877,
      "step": 2480
    },
    {
      "epoch": 0.996,
      "grad_norm": 2.2149417400360107,
      "learning_rate": 1.04e-06,
      "loss": 2.2659,
      "step": 2490
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.183484077453613,
      "learning_rate": 2.4e-07,
      "loss": 2.4603,
      "step": 2500
    }
  ],
  "logging_steps": 10,
  "max_steps": 2500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.1731511631872e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
