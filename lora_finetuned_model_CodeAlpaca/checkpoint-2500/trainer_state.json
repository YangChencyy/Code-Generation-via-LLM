{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 15.911369323730469,
      "learning_rate": 0.00019936000000000002,
      "loss": 9.9987,
      "step": 10
    },
    {
      "epoch": 0.008,
      "grad_norm": 4.36120080947876,
      "learning_rate": 0.00019856000000000002,
      "loss": 1.399,
      "step": 20
    },
    {
      "epoch": 0.012,
      "grad_norm": 2.2189254760742188,
      "learning_rate": 0.00019776,
      "loss": 1.1008,
      "step": 30
    },
    {
      "epoch": 0.016,
      "grad_norm": 6.514350414276123,
      "learning_rate": 0.00019696,
      "loss": 1.0721,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.60456657409668,
      "learning_rate": 0.00019616000000000002,
      "loss": 1.075,
      "step": 50
    },
    {
      "epoch": 0.024,
      "grad_norm": 3.3570077419281006,
      "learning_rate": 0.00019536,
      "loss": 0.849,
      "step": 60
    },
    {
      "epoch": 0.028,
      "grad_norm": 2.7620649337768555,
      "learning_rate": 0.00019456,
      "loss": 0.9344,
      "step": 70
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.503055453300476,
      "learning_rate": 0.00019376000000000002,
      "loss": 0.863,
      "step": 80
    },
    {
      "epoch": 0.036,
      "grad_norm": 1.7573754787445068,
      "learning_rate": 0.00019296,
      "loss": 1.1533,
      "step": 90
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.337691307067871,
      "learning_rate": 0.00019216,
      "loss": 0.6398,
      "step": 100
    },
    {
      "epoch": 0.044,
      "grad_norm": 1.7155451774597168,
      "learning_rate": 0.00019136,
      "loss": 0.8374,
      "step": 110
    },
    {
      "epoch": 0.048,
      "grad_norm": 2.833449125289917,
      "learning_rate": 0.00019056000000000002,
      "loss": 0.7897,
      "step": 120
    },
    {
      "epoch": 0.052,
      "grad_norm": 1.993720293045044,
      "learning_rate": 0.00018976,
      "loss": 0.7592,
      "step": 130
    },
    {
      "epoch": 0.056,
      "grad_norm": 1.2091585397720337,
      "learning_rate": 0.00018896,
      "loss": 0.6425,
      "step": 140
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7894917726516724,
      "learning_rate": 0.00018816000000000001,
      "loss": 0.7662,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 4.825648784637451,
      "learning_rate": 0.00018736,
      "loss": 0.8144,
      "step": 160
    },
    {
      "epoch": 0.068,
      "grad_norm": 1.1998636722564697,
      "learning_rate": 0.00018656,
      "loss": 0.6795,
      "step": 170
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.9595373868942261,
      "learning_rate": 0.00018576,
      "loss": 0.6038,
      "step": 180
    },
    {
      "epoch": 0.076,
      "grad_norm": 2.2514095306396484,
      "learning_rate": 0.00018496,
      "loss": 0.6728,
      "step": 190
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9398595094680786,
      "learning_rate": 0.00018416,
      "loss": 0.718,
      "step": 200
    },
    {
      "epoch": 0.084,
      "grad_norm": 1.2677397727966309,
      "learning_rate": 0.00018336,
      "loss": 1.0194,
      "step": 210
    },
    {
      "epoch": 0.088,
      "grad_norm": 2.0668580532073975,
      "learning_rate": 0.00018256,
      "loss": 0.6549,
      "step": 220
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.8059624433517456,
      "learning_rate": 0.00018176000000000002,
      "loss": 0.7137,
      "step": 230
    },
    {
      "epoch": 0.096,
      "grad_norm": 2.3523032665252686,
      "learning_rate": 0.00018096000000000003,
      "loss": 0.6775,
      "step": 240
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6189864277839661,
      "learning_rate": 0.00018016,
      "loss": 0.8941,
      "step": 250
    },
    {
      "epoch": 0.104,
      "grad_norm": 1.8166223764419556,
      "learning_rate": 0.00017936000000000002,
      "loss": 1.1138,
      "step": 260
    },
    {
      "epoch": 0.108,
      "grad_norm": 1.5767359733581543,
      "learning_rate": 0.00017856000000000003,
      "loss": 0.7436,
      "step": 270
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.9985407590866089,
      "learning_rate": 0.00017776,
      "loss": 0.8158,
      "step": 280
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.982852041721344,
      "learning_rate": 0.00017696,
      "loss": 0.645,
      "step": 290
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.676624059677124,
      "learning_rate": 0.00017616000000000002,
      "loss": 0.8325,
      "step": 300
    },
    {
      "epoch": 0.124,
      "grad_norm": 2.826408624649048,
      "learning_rate": 0.00017536,
      "loss": 0.6854,
      "step": 310
    },
    {
      "epoch": 0.128,
      "grad_norm": 6.951280117034912,
      "learning_rate": 0.00017456,
      "loss": 1.0615,
      "step": 320
    },
    {
      "epoch": 0.132,
      "grad_norm": 3.733030080795288,
      "learning_rate": 0.00017376000000000002,
      "loss": 0.6158,
      "step": 330
    },
    {
      "epoch": 0.136,
      "grad_norm": 1.6553552150726318,
      "learning_rate": 0.00017296,
      "loss": 0.7108,
      "step": 340
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.3369510173797607,
      "learning_rate": 0.00017216,
      "loss": 0.7599,
      "step": 350
    },
    {
      "epoch": 0.144,
      "grad_norm": 2.3190104961395264,
      "learning_rate": 0.00017136,
      "loss": 0.7725,
      "step": 360
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.9938533306121826,
      "learning_rate": 0.00017056000000000002,
      "loss": 0.6312,
      "step": 370
    },
    {
      "epoch": 0.152,
      "grad_norm": 1.9192476272583008,
      "learning_rate": 0.00016976,
      "loss": 0.7061,
      "step": 380
    },
    {
      "epoch": 0.156,
      "grad_norm": 1.1872912645339966,
      "learning_rate": 0.00016896,
      "loss": 0.6437,
      "step": 390
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.2077451944351196,
      "learning_rate": 0.00016816000000000002,
      "loss": 0.7014,
      "step": 400
    },
    {
      "epoch": 0.164,
      "grad_norm": 1.5366723537445068,
      "learning_rate": 0.00016736,
      "loss": 0.9263,
      "step": 410
    },
    {
      "epoch": 0.168,
      "grad_norm": 1.899877905845642,
      "learning_rate": 0.00016656,
      "loss": 0.8088,
      "step": 420
    },
    {
      "epoch": 0.172,
      "grad_norm": 1.1189154386520386,
      "learning_rate": 0.00016576,
      "loss": 0.8926,
      "step": 430
    },
    {
      "epoch": 0.176,
      "grad_norm": 5.03688383102417,
      "learning_rate": 0.00016496,
      "loss": 0.941,
      "step": 440
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.741936445236206,
      "learning_rate": 0.00016416,
      "loss": 0.7842,
      "step": 450
    },
    {
      "epoch": 0.184,
      "grad_norm": 1.52169668674469,
      "learning_rate": 0.00016336,
      "loss": 0.7079,
      "step": 460
    },
    {
      "epoch": 0.188,
      "grad_norm": 1.9985464811325073,
      "learning_rate": 0.00016256,
      "loss": 0.7512,
      "step": 470
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.945098876953125,
      "learning_rate": 0.00016176,
      "loss": 0.9637,
      "step": 480
    },
    {
      "epoch": 0.196,
      "grad_norm": 1.1978145837783813,
      "learning_rate": 0.00016096,
      "loss": 0.865,
      "step": 490
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7311971187591553,
      "learning_rate": 0.00016016,
      "loss": 0.7821,
      "step": 500
    },
    {
      "epoch": 0.204,
      "grad_norm": 2.2291646003723145,
      "learning_rate": 0.00015936,
      "loss": 0.8914,
      "step": 510
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.8020917773246765,
      "learning_rate": 0.00015856,
      "loss": 0.754,
      "step": 520
    },
    {
      "epoch": 0.212,
      "grad_norm": 1.5637246370315552,
      "learning_rate": 0.00015776,
      "loss": 0.9903,
      "step": 530
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.5198631286621094,
      "learning_rate": 0.00015696000000000002,
      "loss": 0.5824,
      "step": 540
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.8146300315856934,
      "learning_rate": 0.00015616000000000002,
      "loss": 1.0006,
      "step": 550
    },
    {
      "epoch": 0.224,
      "grad_norm": 1.1585602760314941,
      "learning_rate": 0.00015536,
      "loss": 0.8958,
      "step": 560
    },
    {
      "epoch": 0.228,
      "grad_norm": 1.0303878784179688,
      "learning_rate": 0.00015456,
      "loss": 0.7713,
      "step": 570
    },
    {
      "epoch": 0.232,
      "grad_norm": 1.8140478134155273,
      "learning_rate": 0.00015376000000000002,
      "loss": 0.9847,
      "step": 580
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.9634720087051392,
      "learning_rate": 0.00015296000000000003,
      "loss": 0.7686,
      "step": 590
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6192177534103394,
      "learning_rate": 0.00015216,
      "loss": 0.5779,
      "step": 600
    },
    {
      "epoch": 0.244,
      "grad_norm": 1.156005859375,
      "learning_rate": 0.00015136000000000001,
      "loss": 0.8671,
      "step": 610
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.794392466545105,
      "learning_rate": 0.00015056000000000002,
      "loss": 0.9301,
      "step": 620
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.9278034567832947,
      "learning_rate": 0.00014976,
      "loss": 0.9633,
      "step": 630
    },
    {
      "epoch": 0.256,
      "grad_norm": 1.2367206811904907,
      "learning_rate": 0.00014896,
      "loss": 0.8451,
      "step": 640
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.2776238918304443,
      "learning_rate": 0.00014816000000000002,
      "loss": 0.7531,
      "step": 650
    },
    {
      "epoch": 0.264,
      "grad_norm": 3.660731077194214,
      "learning_rate": 0.00014736,
      "loss": 0.9278,
      "step": 660
    },
    {
      "epoch": 0.268,
      "grad_norm": 1.8882626295089722,
      "learning_rate": 0.00014656,
      "loss": 0.6679,
      "step": 670
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.7298319935798645,
      "learning_rate": 0.00014576000000000001,
      "loss": 0.5618,
      "step": 680
    },
    {
      "epoch": 0.276,
      "grad_norm": 2.9526939392089844,
      "learning_rate": 0.00014496,
      "loss": 0.5858,
      "step": 690
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.2335205078125,
      "learning_rate": 0.00014416,
      "loss": 0.9822,
      "step": 700
    },
    {
      "epoch": 0.284,
      "grad_norm": 1.6332670450210571,
      "learning_rate": 0.00014336,
      "loss": 0.7186,
      "step": 710
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.8797183036804199,
      "learning_rate": 0.00014256000000000002,
      "loss": 0.9501,
      "step": 720
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.8837907910346985,
      "learning_rate": 0.00014176,
      "loss": 0.708,
      "step": 730
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.6804733276367188,
      "learning_rate": 0.00014096,
      "loss": 0.7151,
      "step": 740
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.2134569883346558,
      "learning_rate": 0.00014016,
      "loss": 0.786,
      "step": 750
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.7629628777503967,
      "learning_rate": 0.00013936,
      "loss": 0.6249,
      "step": 760
    },
    {
      "epoch": 0.308,
      "grad_norm": 3.7073163986206055,
      "learning_rate": 0.00013856,
      "loss": 1.0114,
      "step": 770
    },
    {
      "epoch": 0.312,
      "grad_norm": 7.127991199493408,
      "learning_rate": 0.00013776,
      "loss": 0.923,
      "step": 780
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.8065225481987,
      "learning_rate": 0.00013696,
      "loss": 0.988,
      "step": 790
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.863876223564148,
      "learning_rate": 0.00013616,
      "loss": 0.7303,
      "step": 800
    },
    {
      "epoch": 0.324,
      "grad_norm": 1.9238662719726562,
      "learning_rate": 0.00013536,
      "loss": 0.8359,
      "step": 810
    },
    {
      "epoch": 0.328,
      "grad_norm": 2.2020530700683594,
      "learning_rate": 0.00013455999999999999,
      "loss": 0.7578,
      "step": 820
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.8798745274543762,
      "learning_rate": 0.00013376,
      "loss": 0.882,
      "step": 830
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.7937613129615784,
      "learning_rate": 0.00013296,
      "loss": 0.8645,
      "step": 840
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8788819909095764,
      "learning_rate": 0.00013216,
      "loss": 0.6862,
      "step": 850
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.4886907935142517,
      "learning_rate": 0.00013136000000000002,
      "loss": 0.7386,
      "step": 860
    },
    {
      "epoch": 0.348,
      "grad_norm": 8.166496276855469,
      "learning_rate": 0.00013056000000000002,
      "loss": 0.9711,
      "step": 870
    },
    {
      "epoch": 0.352,
      "grad_norm": 1.5180244445800781,
      "learning_rate": 0.00012976,
      "loss": 0.6202,
      "step": 880
    },
    {
      "epoch": 0.356,
      "grad_norm": 3.9286046028137207,
      "learning_rate": 0.00012896,
      "loss": 0.9266,
      "step": 890
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8864779472351074,
      "learning_rate": 0.00012816000000000002,
      "loss": 0.712,
      "step": 900
    },
    {
      "epoch": 0.364,
      "grad_norm": 2.7221720218658447,
      "learning_rate": 0.00012736,
      "loss": 0.7595,
      "step": 910
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.8967341184616089,
      "learning_rate": 0.00012656,
      "loss": 0.8045,
      "step": 920
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.43204978108406067,
      "learning_rate": 0.00012576000000000002,
      "loss": 0.6011,
      "step": 930
    },
    {
      "epoch": 0.376,
      "grad_norm": 1.8186454772949219,
      "learning_rate": 0.00012496000000000002,
      "loss": 0.7626,
      "step": 940
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9823172092437744,
      "learning_rate": 0.00012416,
      "loss": 0.7678,
      "step": 950
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.7601703405380249,
      "learning_rate": 0.00012336,
      "loss": 0.6184,
      "step": 960
    },
    {
      "epoch": 0.388,
      "grad_norm": 1.3564621210098267,
      "learning_rate": 0.00012256000000000002,
      "loss": 1.0401,
      "step": 970
    },
    {
      "epoch": 0.392,
      "grad_norm": 1.0547568798065186,
      "learning_rate": 0.00012176000000000001,
      "loss": 0.7906,
      "step": 980
    },
    {
      "epoch": 0.396,
      "grad_norm": 1.0401556491851807,
      "learning_rate": 0.00012096000000000001,
      "loss": 0.6421,
      "step": 990
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.9453768730163574,
      "learning_rate": 0.00012016,
      "loss": 0.7601,
      "step": 1000
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.5818959474563599,
      "learning_rate": 0.00011936000000000001,
      "loss": 0.6914,
      "step": 1010
    },
    {
      "epoch": 0.408,
      "grad_norm": 1.3113000392913818,
      "learning_rate": 0.00011856,
      "loss": 0.7912,
      "step": 1020
    },
    {
      "epoch": 0.412,
      "grad_norm": 1.7192832231521606,
      "learning_rate": 0.00011776,
      "loss": 0.6915,
      "step": 1030
    },
    {
      "epoch": 0.416,
      "grad_norm": 1.6424574851989746,
      "learning_rate": 0.00011696,
      "loss": 0.7768,
      "step": 1040
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3010612726211548,
      "learning_rate": 0.00011616,
      "loss": 0.6277,
      "step": 1050
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.9997023940086365,
      "learning_rate": 0.00011536000000000001,
      "loss": 0.7139,
      "step": 1060
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.9758412837982178,
      "learning_rate": 0.00011456,
      "loss": 0.7035,
      "step": 1070
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.7841740846633911,
      "learning_rate": 0.00011376,
      "loss": 0.6831,
      "step": 1080
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.6637563705444336,
      "learning_rate": 0.00011296,
      "loss": 0.7198,
      "step": 1090
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.9021610617637634,
      "learning_rate": 0.00011216,
      "loss": 0.6448,
      "step": 1100
    },
    {
      "epoch": 0.444,
      "grad_norm": 1.087491750717163,
      "learning_rate": 0.00011135999999999999,
      "loss": 0.6982,
      "step": 1110
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.6269547939300537,
      "learning_rate": 0.00011056,
      "loss": 0.8255,
      "step": 1120
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.5225562453269958,
      "learning_rate": 0.00010975999999999999,
      "loss": 0.9787,
      "step": 1130
    },
    {
      "epoch": 0.456,
      "grad_norm": 1.2889596223831177,
      "learning_rate": 0.00010896,
      "loss": 0.7763,
      "step": 1140
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.8126487135887146,
      "learning_rate": 0.00010816,
      "loss": 0.838,
      "step": 1150
    },
    {
      "epoch": 0.464,
      "grad_norm": 1.8189607858657837,
      "learning_rate": 0.00010736000000000002,
      "loss": 0.6722,
      "step": 1160
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.6243427991867065,
      "learning_rate": 0.00010656000000000001,
      "loss": 0.6731,
      "step": 1170
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.6291114091873169,
      "learning_rate": 0.00010576000000000002,
      "loss": 0.6237,
      "step": 1180
    },
    {
      "epoch": 0.476,
      "grad_norm": 1.1123719215393066,
      "learning_rate": 0.00010496000000000001,
      "loss": 0.6867,
      "step": 1190
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.1827000379562378,
      "learning_rate": 0.00010416000000000002,
      "loss": 0.6214,
      "step": 1200
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.5947415232658386,
      "learning_rate": 0.00010336000000000001,
      "loss": 0.7368,
      "step": 1210
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.9577105641365051,
      "learning_rate": 0.00010256000000000001,
      "loss": 0.7418,
      "step": 1220
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.5780540704727173,
      "learning_rate": 0.00010176000000000002,
      "loss": 0.7516,
      "step": 1230
    },
    {
      "epoch": 0.496,
      "grad_norm": 2.334695816040039,
      "learning_rate": 0.00010096000000000001,
      "loss": 0.918,
      "step": 1240
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7579830884933472,
      "learning_rate": 0.00010016,
      "loss": 0.5614,
      "step": 1250
    },
    {
      "epoch": 0.504,
      "grad_norm": 1.123275876045227,
      "learning_rate": 9.936000000000001e-05,
      "loss": 0.9452,
      "step": 1260
    },
    {
      "epoch": 0.508,
      "grad_norm": 1.9391707181930542,
      "learning_rate": 9.856e-05,
      "loss": 0.688,
      "step": 1270
    },
    {
      "epoch": 0.512,
      "grad_norm": 3.3138527870178223,
      "learning_rate": 9.776000000000001e-05,
      "loss": 0.849,
      "step": 1280
    },
    {
      "epoch": 0.516,
      "grad_norm": 3.0829696655273438,
      "learning_rate": 9.696000000000001e-05,
      "loss": 0.7388,
      "step": 1290
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0344040393829346,
      "learning_rate": 9.616e-05,
      "loss": 0.7097,
      "step": 1300
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.5277001261711121,
      "learning_rate": 9.536000000000001e-05,
      "loss": 0.7424,
      "step": 1310
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.575339674949646,
      "learning_rate": 9.456e-05,
      "loss": 0.6719,
      "step": 1320
    },
    {
      "epoch": 0.532,
      "grad_norm": 1.2060105800628662,
      "learning_rate": 9.376e-05,
      "loss": 0.8064,
      "step": 1330
    },
    {
      "epoch": 0.536,
      "grad_norm": 1.6105650663375854,
      "learning_rate": 9.296e-05,
      "loss": 0.5363,
      "step": 1340
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8021818399429321,
      "learning_rate": 9.216e-05,
      "loss": 0.8746,
      "step": 1350
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.8340069651603699,
      "learning_rate": 9.136e-05,
      "loss": 0.6697,
      "step": 1360
    },
    {
      "epoch": 0.548,
      "grad_norm": 2.2623047828674316,
      "learning_rate": 9.056e-05,
      "loss": 0.7216,
      "step": 1370
    },
    {
      "epoch": 0.552,
      "grad_norm": 1.179520606994629,
      "learning_rate": 8.976e-05,
      "loss": 0.8231,
      "step": 1380
    },
    {
      "epoch": 0.556,
      "grad_norm": 1.2460424900054932,
      "learning_rate": 8.896e-05,
      "loss": 0.5805,
      "step": 1390
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6582365036010742,
      "learning_rate": 8.816000000000001e-05,
      "loss": 0.7926,
      "step": 1400
    },
    {
      "epoch": 0.564,
      "grad_norm": 1.637494683265686,
      "learning_rate": 8.736e-05,
      "loss": 0.5734,
      "step": 1410
    },
    {
      "epoch": 0.568,
      "grad_norm": 1.1899082660675049,
      "learning_rate": 8.656000000000001e-05,
      "loss": 0.6722,
      "step": 1420
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.9904876947402954,
      "learning_rate": 8.576e-05,
      "loss": 0.7576,
      "step": 1430
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.8723271489143372,
      "learning_rate": 8.496e-05,
      "loss": 0.6822,
      "step": 1440
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7791007161140442,
      "learning_rate": 8.416000000000001e-05,
      "loss": 0.6617,
      "step": 1450
    },
    {
      "epoch": 0.584,
      "grad_norm": 1.5059162378311157,
      "learning_rate": 8.336e-05,
      "loss": 0.869,
      "step": 1460
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.841596245765686,
      "learning_rate": 8.256000000000001e-05,
      "loss": 0.7851,
      "step": 1470
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.45720863342285156,
      "learning_rate": 8.176e-05,
      "loss": 0.587,
      "step": 1480
    },
    {
      "epoch": 0.596,
      "grad_norm": 1.7391817569732666,
      "learning_rate": 8.096e-05,
      "loss": 0.5662,
      "step": 1490
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.6256765127182007,
      "learning_rate": 8.016e-05,
      "loss": 0.6375,
      "step": 1500
    },
    {
      "epoch": 0.604,
      "grad_norm": 1.4469670057296753,
      "learning_rate": 7.936e-05,
      "loss": 0.6308,
      "step": 1510
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.5113074779510498,
      "learning_rate": 7.856000000000001e-05,
      "loss": 0.938,
      "step": 1520
    },
    {
      "epoch": 0.612,
      "grad_norm": 1.3235348463058472,
      "learning_rate": 7.776e-05,
      "loss": 0.7295,
      "step": 1530
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.42665618658065796,
      "learning_rate": 7.696e-05,
      "loss": 0.527,
      "step": 1540
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.989955484867096,
      "learning_rate": 7.616e-05,
      "loss": 0.8172,
      "step": 1550
    },
    {
      "epoch": 0.624,
      "grad_norm": 1.054854154586792,
      "learning_rate": 7.536000000000001e-05,
      "loss": 0.6405,
      "step": 1560
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.8538710474967957,
      "learning_rate": 7.456e-05,
      "loss": 0.5888,
      "step": 1570
    },
    {
      "epoch": 0.632,
      "grad_norm": 1.2848588228225708,
      "learning_rate": 7.376000000000001e-05,
      "loss": 0.6216,
      "step": 1580
    },
    {
      "epoch": 0.636,
      "grad_norm": 1.8218806982040405,
      "learning_rate": 7.296e-05,
      "loss": 0.6197,
      "step": 1590
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9215025901794434,
      "learning_rate": 7.216e-05,
      "loss": 0.8223,
      "step": 1600
    },
    {
      "epoch": 0.644,
      "grad_norm": 1.3051800727844238,
      "learning_rate": 7.136000000000001e-05,
      "loss": 0.7628,
      "step": 1610
    },
    {
      "epoch": 0.648,
      "grad_norm": 2.8587028980255127,
      "learning_rate": 7.056e-05,
      "loss": 0.7808,
      "step": 1620
    },
    {
      "epoch": 0.652,
      "grad_norm": 1.0892558097839355,
      "learning_rate": 6.976000000000001e-05,
      "loss": 0.7228,
      "step": 1630
    },
    {
      "epoch": 0.656,
      "grad_norm": 2.5166890621185303,
      "learning_rate": 6.896e-05,
      "loss": 0.6766,
      "step": 1640
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1517150402069092,
      "learning_rate": 6.816e-05,
      "loss": 0.6892,
      "step": 1650
    },
    {
      "epoch": 0.664,
      "grad_norm": 1.314408540725708,
      "learning_rate": 6.736e-05,
      "loss": 0.6073,
      "step": 1660
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.5233767032623291,
      "learning_rate": 6.656e-05,
      "loss": 0.7708,
      "step": 1670
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.7926772236824036,
      "learning_rate": 6.576e-05,
      "loss": 0.5525,
      "step": 1680
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.8576917052268982,
      "learning_rate": 6.496e-05,
      "loss": 0.5687,
      "step": 1690
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5906118154525757,
      "learning_rate": 6.416e-05,
      "loss": 0.6685,
      "step": 1700
    },
    {
      "epoch": 0.684,
      "grad_norm": 1.504826545715332,
      "learning_rate": 6.336e-05,
      "loss": 0.747,
      "step": 1710
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.5950374603271484,
      "learning_rate": 6.256000000000001e-05,
      "loss": 0.7282,
      "step": 1720
    },
    {
      "epoch": 0.692,
      "grad_norm": 1.5671122074127197,
      "learning_rate": 6.176e-05,
      "loss": 0.9763,
      "step": 1730
    },
    {
      "epoch": 0.696,
      "grad_norm": 1.5781781673431396,
      "learning_rate": 6.0960000000000006e-05,
      "loss": 0.5744,
      "step": 1740
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.3755594491958618,
      "learning_rate": 6.016000000000001e-05,
      "loss": 0.5746,
      "step": 1750
    },
    {
      "epoch": 0.704,
      "grad_norm": 1.3149280548095703,
      "learning_rate": 5.936000000000001e-05,
      "loss": 0.6953,
      "step": 1760
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.6255134344100952,
      "learning_rate": 5.856e-05,
      "loss": 0.6433,
      "step": 1770
    },
    {
      "epoch": 0.712,
      "grad_norm": 1.287431240081787,
      "learning_rate": 5.776e-05,
      "loss": 0.7703,
      "step": 1780
    },
    {
      "epoch": 0.716,
      "grad_norm": 2.448530912399292,
      "learning_rate": 5.6960000000000004e-05,
      "loss": 0.7198,
      "step": 1790
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.9661381244659424,
      "learning_rate": 5.6160000000000004e-05,
      "loss": 0.8976,
      "step": 1800
    },
    {
      "epoch": 0.724,
      "grad_norm": 1.053928017616272,
      "learning_rate": 5.536e-05,
      "loss": 0.8902,
      "step": 1810
    },
    {
      "epoch": 0.728,
      "grad_norm": 2.109332323074341,
      "learning_rate": 5.456e-05,
      "loss": 0.8241,
      "step": 1820
    },
    {
      "epoch": 0.732,
      "grad_norm": 8.077532768249512,
      "learning_rate": 5.376e-05,
      "loss": 0.8832,
      "step": 1830
    },
    {
      "epoch": 0.736,
      "grad_norm": 2.438138484954834,
      "learning_rate": 5.296e-05,
      "loss": 0.6254,
      "step": 1840
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.622848629951477,
      "learning_rate": 5.2159999999999995e-05,
      "loss": 0.6415,
      "step": 1850
    },
    {
      "epoch": 0.744,
      "grad_norm": 2.0573372840881348,
      "learning_rate": 5.1359999999999996e-05,
      "loss": 0.6177,
      "step": 1860
    },
    {
      "epoch": 0.748,
      "grad_norm": 1.2728288173675537,
      "learning_rate": 5.056000000000001e-05,
      "loss": 0.8,
      "step": 1870
    },
    {
      "epoch": 0.752,
      "grad_norm": 1.0358394384384155,
      "learning_rate": 4.976e-05,
      "loss": 0.6938,
      "step": 1880
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.682930588722229,
      "learning_rate": 4.896e-05,
      "loss": 0.6637,
      "step": 1890
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.4832632541656494,
      "learning_rate": 4.816e-05,
      "loss": 0.9789,
      "step": 1900
    },
    {
      "epoch": 0.764,
      "grad_norm": 2.679084062576294,
      "learning_rate": 4.736000000000001e-05,
      "loss": 0.7846,
      "step": 1910
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.5406474471092224,
      "learning_rate": 4.656e-05,
      "loss": 0.6378,
      "step": 1920
    },
    {
      "epoch": 0.772,
      "grad_norm": 1.976682424545288,
      "learning_rate": 4.576e-05,
      "loss": 0.6604,
      "step": 1930
    },
    {
      "epoch": 0.776,
      "grad_norm": 1.0284980535507202,
      "learning_rate": 4.496e-05,
      "loss": 1.0664,
      "step": 1940
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.1739426851272583,
      "learning_rate": 4.4160000000000004e-05,
      "loss": 0.7373,
      "step": 1950
    },
    {
      "epoch": 0.784,
      "grad_norm": 1.859352469444275,
      "learning_rate": 4.336e-05,
      "loss": 0.9391,
      "step": 1960
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.989990770816803,
      "learning_rate": 4.256e-05,
      "loss": 0.6032,
      "step": 1970
    },
    {
      "epoch": 0.792,
      "grad_norm": 1.235122799873352,
      "learning_rate": 4.176000000000001e-05,
      "loss": 0.5968,
      "step": 1980
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.5871925354003906,
      "learning_rate": 4.096e-05,
      "loss": 0.9567,
      "step": 1990
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.816413164138794,
      "learning_rate": 4.016e-05,
      "loss": 0.7865,
      "step": 2000
    },
    {
      "epoch": 0.804,
      "grad_norm": 1.237973690032959,
      "learning_rate": 3.936e-05,
      "loss": 0.9236,
      "step": 2010
    },
    {
      "epoch": 0.808,
      "grad_norm": 1.7463194131851196,
      "learning_rate": 3.8560000000000004e-05,
      "loss": 0.6384,
      "step": 2020
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.7530282735824585,
      "learning_rate": 3.776e-05,
      "loss": 0.6353,
      "step": 2030
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.5443562865257263,
      "learning_rate": 3.696e-05,
      "loss": 0.8301,
      "step": 2040
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.0763670206069946,
      "learning_rate": 3.616e-05,
      "loss": 0.6413,
      "step": 2050
    },
    {
      "epoch": 0.824,
      "grad_norm": 1.35361647605896,
      "learning_rate": 3.536000000000001e-05,
      "loss": 0.8037,
      "step": 2060
    },
    {
      "epoch": 0.828,
      "grad_norm": 1.4546911716461182,
      "learning_rate": 3.456e-05,
      "loss": 0.6849,
      "step": 2070
    },
    {
      "epoch": 0.832,
      "grad_norm": 6.773502349853516,
      "learning_rate": 3.376e-05,
      "loss": 0.9904,
      "step": 2080
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.7281890511512756,
      "learning_rate": 3.296e-05,
      "loss": 0.7846,
      "step": 2090
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7221150398254395,
      "learning_rate": 3.2160000000000004e-05,
      "loss": 0.6794,
      "step": 2100
    },
    {
      "epoch": 0.844,
      "grad_norm": 1.0038328170776367,
      "learning_rate": 3.136e-05,
      "loss": 0.6451,
      "step": 2110
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.8642178773880005,
      "learning_rate": 3.056e-05,
      "loss": 0.6371,
      "step": 2120
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.5452098846435547,
      "learning_rate": 2.976e-05,
      "loss": 0.623,
      "step": 2130
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.8120440244674683,
      "learning_rate": 2.8960000000000004e-05,
      "loss": 0.6566,
      "step": 2140
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.0018399953842163,
      "learning_rate": 2.816e-05,
      "loss": 0.8779,
      "step": 2150
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.616207242012024,
      "learning_rate": 2.7360000000000002e-05,
      "loss": 0.737,
      "step": 2160
    },
    {
      "epoch": 0.868,
      "grad_norm": 1.3126682043075562,
      "learning_rate": 2.6560000000000003e-05,
      "loss": 0.7292,
      "step": 2170
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.514779269695282,
      "learning_rate": 2.576e-05,
      "loss": 0.756,
      "step": 2180
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.7708933353424072,
      "learning_rate": 2.496e-05,
      "loss": 0.7198,
      "step": 2190
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.42296451330184937,
      "learning_rate": 2.4160000000000002e-05,
      "loss": 0.8452,
      "step": 2200
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.935490608215332,
      "learning_rate": 2.336e-05,
      "loss": 0.6267,
      "step": 2210
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.5747727751731873,
      "learning_rate": 2.256e-05,
      "loss": 0.7095,
      "step": 2220
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.6244743466377258,
      "learning_rate": 2.176e-05,
      "loss": 0.6066,
      "step": 2230
    },
    {
      "epoch": 0.896,
      "grad_norm": 1.8913366794586182,
      "learning_rate": 2.0960000000000003e-05,
      "loss": 0.8168,
      "step": 2240
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.0114176273345947,
      "learning_rate": 2.016e-05,
      "loss": 0.5895,
      "step": 2250
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.720528781414032,
      "learning_rate": 1.936e-05,
      "loss": 0.9056,
      "step": 2260
    },
    {
      "epoch": 0.908,
      "grad_norm": 1.3502222299575806,
      "learning_rate": 1.856e-05,
      "loss": 0.5031,
      "step": 2270
    },
    {
      "epoch": 0.912,
      "grad_norm": 1.5717430114746094,
      "learning_rate": 1.7760000000000003e-05,
      "loss": 0.6963,
      "step": 2280
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.6548409461975098,
      "learning_rate": 1.696e-05,
      "loss": 0.6618,
      "step": 2290
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8919354677200317,
      "learning_rate": 1.616e-05,
      "loss": 0.7277,
      "step": 2300
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.47279980778694153,
      "learning_rate": 1.536e-05,
      "loss": 0.6669,
      "step": 2310
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.9489601850509644,
      "learning_rate": 1.4560000000000001e-05,
      "loss": 0.9217,
      "step": 2320
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.5640581846237183,
      "learning_rate": 1.376e-05,
      "loss": 0.5715,
      "step": 2330
    },
    {
      "epoch": 0.936,
      "grad_norm": 1.4674755334854126,
      "learning_rate": 1.296e-05,
      "loss": 0.9034,
      "step": 2340
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5783116817474365,
      "learning_rate": 1.216e-05,
      "loss": 0.6767,
      "step": 2350
    },
    {
      "epoch": 0.944,
      "grad_norm": 1.0735604763031006,
      "learning_rate": 1.1360000000000001e-05,
      "loss": 0.7349,
      "step": 2360
    },
    {
      "epoch": 0.948,
      "grad_norm": 1.2423182725906372,
      "learning_rate": 1.056e-05,
      "loss": 0.7811,
      "step": 2370
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.5540382862091064,
      "learning_rate": 9.760000000000001e-06,
      "loss": 0.657,
      "step": 2380
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.5265305638313293,
      "learning_rate": 8.96e-06,
      "loss": 0.6011,
      "step": 2390
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.864809513092041,
      "learning_rate": 8.160000000000001e-06,
      "loss": 0.8827,
      "step": 2400
    },
    {
      "epoch": 0.964,
      "grad_norm": 1.8536511659622192,
      "learning_rate": 7.36e-06,
      "loss": 0.7649,
      "step": 2410
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.4119319021701813,
      "learning_rate": 6.560000000000001e-06,
      "loss": 0.6076,
      "step": 2420
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.6526763439178467,
      "learning_rate": 5.76e-06,
      "loss": 0.6505,
      "step": 2430
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.6369462609291077,
      "learning_rate": 4.96e-06,
      "loss": 0.6122,
      "step": 2440
    },
    {
      "epoch": 0.98,
      "grad_norm": 4.19199275970459,
      "learning_rate": 4.16e-06,
      "loss": 0.7146,
      "step": 2450
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.439155250787735,
      "learning_rate": 3.36e-06,
      "loss": 0.8871,
      "step": 2460
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.754459023475647,
      "learning_rate": 2.56e-06,
      "loss": 0.7122,
      "step": 2470
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.3273521065711975,
      "learning_rate": 1.76e-06,
      "loss": 0.9319,
      "step": 2480
    },
    {
      "epoch": 0.996,
      "grad_norm": 1.3194321393966675,
      "learning_rate": 9.6e-07,
      "loss": 0.6225,
      "step": 2490
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.3960788249969482,
      "learning_rate": 1.6e-07,
      "loss": 1.0104,
      "step": 2500
    }
  ],
  "logging_steps": 10,
  "max_steps": 2500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.1731511631872e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
